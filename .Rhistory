military_labor_force = "B23025_006",
non_labor_force = "B23025_007",
agg_income_deficit = "B17011_001",
agg_income_deficit_married = "B17011_002",
agg_income_deficit_nonmarried = "B17011_003",
agg_income_deficit_no_wife = "B17011_004",
agg_income_deficit_no_husband = "B17011_005",
median_household_income = "B25119_001",
median_hh_income_own = "B25119_002",
median_hh_income_rent = "B25119_003",
no_schooling_completed = "B15003_002",
nursery_school = "B15003_003",
kindergarten = "B15003_004",
first_grade = "B15003_005",
second_grade = "B15003_006",
third_grade = "B15003_007",
fourth_grade = "B15003_008",
fifth_grade = "B15003_009",
sixth_grade = "B15003_010",
seventh_grade = "B15003_011",
eigth_grade = "B15003_012",
ninth_grade = "B15003_013",
tenth_grade = "B15003_014",
eleventh_grade = "B15003_015",
twelfth_grade_no_diploma = "B15003_016",
regular_high_school_diploma = "B15003_017",
ged_or_alternative_credential = "B15003_018",
some_college_less_than_1_year = "B15003_019",
some_college_1_or_more_years_no_degree = "B15003_020",
associates_degree = "B15003_021",
bachelors_degree = "B15003_022",
masters_degree = "B15003_023",
professional_school_degree = "B15003_024",
doctorate_degree = "B15003_025",
commute_car_truck_or_van = "B08301_002",
commute_drove_alone = "B08301_003",
commute_carpooled = "B08301_004",
commute_in_2_person_carpool = "B08301_005",
commute_in_3_person_carpool = "B08301_006",
commute_in_4_person_carpool = "B08301_007",
commute_in_5_or_6_person_carpool = "B08301_008",
commute_in_7_or_more_person_carpool = "B08301_009",
commute_public_transportation_excluding_taxicab = "B08301_010",
commute_bus_or_trolley_bus = "B08301_011",
commute_streetcar_or_trolley_car = "B08301_012",
commute_subway_or_elevated = "B08301_013",
commute_railroad = "B08301_014",
commute_ferryboat = "B08301_015",
commute_taxicab = "B08301_016",
commute_motorcycle = "B08301_017",
commute_bicycle = "B08301_018",
commute_walked = "B08301_019",
commute_other_means = "B08301_020",
commute_worked_at_home = "B08301_021",
hh_income_less_than_10000 = 'B19001_002',
hh_income_10000_to_14999 = 'B19001_003',
hh_income_15000_to_19999 = 'B19001_004',
hh_income_20000_to_24999 = 'B19001_005',
hh_income_25000_to_29999 = 'B19001_006',
hh_income_30000_to_34999 = 'B19001_007',
hh_income_35000_to_39999 = 'B19001_008',
hh_income_40000_to_44999 = 'B19001_009',
hh_income_45000_to_49999 = 'B19001_010',
hh_income_50000_to_59999 = 'B19001_011',
hh_income_60000_to_74999 = 'B19001_012',
hh_income_75000_to_99999 = 'B19001_013',
hh_income_100000_to_124999 = 'B19001_014',
hh_income_125000_to_149999 = 'B19001_015',
hh_income_150000_to_199999 = 'B19001_016',
hh_income_200_000_or_more = 'B19001_017',
workers_no_vehicle_available = 'B08014_002',
workers_1_vehicle_available = 'B08014_003',
workers_2_vehicles_available = 'B08014_004',
workers_3_vehicles_available = 'B08014_005',
workers_4_vehicles_available = 'B08014_006',
workers_5_plus_vehicles_available = 'B08014_007'
)
acs2017Variables <- load_variables(2017, "acs5", cache = TRUE)
pulled_vars <- data.frame(censusVars, stringsAsFactors = F) %>%
inner_join(acs2017Variables, by = c("censusVars" = "name"))
pulled_vars$variable_name <- names(censusVars)
pulled_vars <- pulled_vars %>%
select(variable_name, everything())
write.csv(pulled_vars, "Pulled_Variables.csv", row.names = F)
stJoesTract <- get_acs(
geography = "tract",
variables = censusVars,
state = "IN",
county = "St. Joseph County",
output = "wide",
geometry = FALSE
)
stJoesBlockGroup <- get_acs(
geography = "block group",
variables = censusVars,
state = "IN",
county = "St. Joseph County",
output = "wide",
geometry = FALSE
)
#Split NAME into separate columns
stJoesBlockGroup$BlockGroup <- apply(stJoesBlockGroup[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][1]})
stJoesBlockGroup$CensusTract <- apply(stJoesBlockGroup[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][2]})
stJoesBlockGroup$County <- apply(stJoesBlockGroup[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][3]})
stJoesBlockGroup$State <- apply(stJoesBlockGroup[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][4]})
#Split NAME into separate columns
stJoesTract$CensusTract <- apply(stJoesTract[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][1]})
stJoesTract$County <- apply(stJoesTract[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][2]})
stJoesTract$State <- apply(stJoesTract[, 'NAME'], 1, function(x){str_split(x, pattern = ", ")[[1]][3]})
save(stJoesTract, stJoesBlockGroup, file = "census_data.RData")
stJoesTractCSV <- stJoesTract %>%
select(CensusTract, County, State, everything()) %>%
select(-ends_with('M', ignore.case = F), -GEOID, -NAME)
colnames(stJoesTractCSV)[4:ncol(stJoesTractCSV)] <- names(censusVars)
stJoesBlockGroupCSV <- stJoesBlockGroup %>%
select(BlockGroup, CensusTract, County, State, everything()) %>%
select(-ends_with('M', ignore.case = F), -GEOID, -NAME)
colnames(stJoesBlockGroupCSV)[5:ncol(stJoesBlockGroupCSV)] <- names(censusVars)
write.csv(stJoesTractCSV, "St_Joes_Tract_Data.csv", row.names = F)
write.csv(stJoesBlockGroupCSV, "St_Joes_Block_Group_Data.csv", row.names = F)
library(tidycensus)
library(dplyr)
library(stringr)
library(leaflet)
setwd("~/GitHub/DS-Now-Final-Project")
#Load the data
load("census_data.RData")
#Get rid of margins of error for now
minus_margins_tr <- stJoesTract %>%
select(-ends_with('M', ignore.case = F))
#Get rid of margins of error for now
minus_margins_bg <- stJoesBlockGroup %>%
select(-ends_with('M', ignore.case = F))
#Find the number of missing values for each dataset
tract_nas <- sapply(minus_margins_tr, function(x){sum(is.na(x))})
bg_nas <- sapply(minus_margins_bg, function(x){sum(is.na(x))})
bg_nas[bg_nas > 0]
tract_nas[tract_nas > 0]
#Filter columns with an NA's
filtered_bg <- minus_margins_bg[, bg_nas == 0]
#Filter columns with an NA's
filtered_tr <- minus_margins_tr[, tract_nas == 0]
??pca
View(minus_margins_bg)
View(minus_margins_bg)
View(minus_margins_bg)
View(minus_margins_bg)
View(filtered_bg)
View(filtered_bg)
filtered_bg[, 3]
filtered_bg[, 3:(ncol(filtered_bg)-4)]
prcomp(x = filtered_bg[, 3:(ncol(filtered_bg)-4)], center = TRUE,scale. = TRUE)
#Scale values for clustering
scaled_bg <- filtered_bg %>%
select_if(is.numeric) %>%
scale() %>%
as_tibble()
tract_unique <- sapply(minus_margins_tr, function(x){length(unique(x))})
bg_unique <- sapply(minus_margins_bg, function(x){length(unique(x))})
bg_unique[bg_unique == 0]
bg_unique[bg_unique == 1]
#Filter columns with an NA's
filtered_bg <- minus_margins_bg[, bg_nas == 0 & bg_unique > 1]
#Filter columns with an NA's
filtered_tr <- minus_margins_tr[, tract_nas == 0]
prcomp(x = filtered_bg[, 3:(ncol(filtered_bg)-4)], center = TRUE,scale. = TRUE)
pca_bg <- prcomp(x = filtered_bg[, 3:(ncol(filtered_bg)-4)], center = TRUE,scale. = TRUE)
pca_bg
pca_bg$x
pca_bg$scale
pca_bg$center
pca_bg$rotation
summary(pca_bg)
1e0
pca_bg <- prcomp(x = filtered_bg[, 3:(ncol(filtered_bg)-4)],rank. = 30, center = TRUE,scale. = TRUE)
summary(pca_bg)
acs2018Variables <- load_variables(2018, "acs5", cache = TRUE)
stJoesTract <- get_acs(
geography = "tract",
variables = censusVars,
state = "IN",
county = "St. Joseph County",
output = "wide",
geometry = FALSE,year = 2018
)
stJoesBlockGroup %>%
group_by(NAME) %>%
summarize(pop = sum(total_populationE))
stJoesBlockGroup %>%
summarize(pop = sum(total_populationE))
stJoesTract %>%
summarize(pop = sum(total_populationE))
pca_bg$x
install.packages("GWRM")
library(GWRM)
data("goals")
head(goals)
##Fit Poisson model for comparison
mod_pois <- glm(goals ~ ., family = poisson, data = goals)
summary(mod_pois)
#assess model fit
pchisq(mod_pois$deviance, mod_pois$df.residual,lower=F)
#Assess overdispersion
dispersiontest(mod_pois, alternative = "greater")
??dispersiontest
library(AER)
#Assess overdispersion
dispersiontest(mod_pois, alternative = "greater")
?dispersiontest
mod_negb <- glm.nb(goals ~ ., data = goals)
library(MASS)
mod_negb <- glm.nb(goals ~ ., data = goals)
summary(mod_negb)
#conduct deviance test
pchisq(mod_negb$deviance,mod_negb$df.residual,lower.tail = F)
#conduct deviance test
pchisq(mod_negb$deviance, mod_negb$df.residual, lower.tail = F)
#assess model fit
pchisq(mod_pois$deviance, mod_pois$df.residual,lower=F)
pcount_pois <- colSums(predprob(mod_pois))[0:10]
library(glmbb)
library(pscl)
install.packages("psci")
install.packages("pscl")
library(pscl)
pcount_pois <- colSums(predprob(mod_pois))[0:10]
pcount_pois <- colSums(predprob(mod_pois))[0:10]
#Compute predicted probabilities and # of crabs with 0,1...satellites. Compare to Poisson
ocount <- table(crabs$satell)[0:10]
pcount_negb <- colSums(predprob(mod_negb))[0:10]
#Look at observed vs. predicted side by side and plot
data.frame(ocount,pcount_pois,pcount_negb)
plot(pcount_negb,ocount,type="n",xlab="Predicted",ylab="Observed")
text(pcount_negb,ocount,0:9)
abline(0,1)
#Look at observed vs. predicted side by side and plot
data.frame(ocount,pcount_pois,pcount_negb)
#Compute predicted probabilities and # of crabs with 0,1...satellites. Compare to Poisson
ocount <- table(goals$goals)[0:10]
pcount_negb <- colSums(predprob(mod_negb))[0:10]
#Look at observed vs. predicted side by side and plot
data.frame(ocount,pcount_pois,pcount_negb)
plot(pcount_negb,ocount,type="n",xlab="Predicted",ylab="Observed")
text(pcount_negb,ocount,0:9)
mod_zip <- zeroinfl(goals ~ ., data = goals)
mod_zip_nb <- zeroinfl(goals ~ ., data = goals, dist = "negbin")
AIC(mod_pois)
AIC(mod_negb);AIC(zip1);AIC(zinb1)
AIC(mod_pois)
AIC(mod_negb)
AIC(mod_zip)
AIC(mod_zip_nb)
vuong(mod_pois,mod_zip)
vuong(mod_negb,mod_zip_nb)
pcount_zip_nb <- colSums(predprob(mod_zip))[0:10]
pcount_zip_nb <- colSums(predprob(mod_zip_nb))[0:10]
pcount_zip <- colSums(predprob(mod_zip))[0:10]
data.frame(ocount,pcount_pois,pcount_negb,pcount_zip,pcount_zip_nb)
pcount_zip <- colSums(predprob(mod_zip))[0:30]
pcount_zip_nb <- colSums(predprob(mod_zip_nb))[0:30]
data.frame(ocount,pcount_pois,pcount_negb,pcount_zip,pcount_zip_nb)
pcount_pois <- colSums(predprob(mod_pois))[0:30]
#Compute predicted probabilities and # of crabs with 0,1...satellites. Compare to Poisson
ocount <- table(goals$goals)[0:30]
pcount_negb <- colSums(predprob(mod_negb))[0:30]
#Look at observed vs. predicted side by side and plot
data.frame(ocount,pcount_pois,pcount_negb)
plot(pcount_negb,ocount,type="n",xlab="Predicted",ylab="Observed")
text(pcount_negb,ocount,0:9)
abline(0,1)
mod_zip <- zeroinfl(goals ~ ., data = goals)
mod_zip_nb <- zeroinfl(goals ~ ., data = goals, dist = "negbin")
vuong(mod_pois,mod_zip)
vuong(mod_negb,mod_zip_nb)
AIC(mod_pois)
AIC(mod_negb)
AIC(mod_zip)
AIC(mod_zip_nb)
pcount_zip <- colSums(predprob(mod_zip))[0:30]
pcount_zip_nb <- colSums(predprob(mod_zip_nb))[0:30]
data.frame(ocount,pcount_pois,pcount_negb,pcount_zip,pcount_zip_nb)
setwd("~/GitHub/DS-Now-Final-Project")
library(tidycensus)
library(dplyr)
library(stringr)
library(leaflet)
setwd("~/GitHub/DS-Now-Final-Project")
#Load the data
load("census_data.RData")
#Get rid of margins of error for now
minus_margins_tr <- stJoesTract %>%
select(-ends_with('M', ignore.case = F))
#Get rid of margins of error for now
minus_margins_bg <- stJoesBlockGroup %>%
select(-ends_with('M', ignore.case = F))
#Find the number of missing values for each dataset
tract_nas <- sapply(minus_margins_tr, function(x){sum(is.na(x))})
bg_nas <- sapply(minus_margins_bg, function(x){sum(is.na(x))})
bg_nas[bg_nas > 0]
tract_nas[tract_nas > 0]
tract_unique <- sapply(minus_margins_tr, function(x){length(unique(x))})
bg_unique <- sapply(minus_margins_bg, function(x){length(unique(x))})
bg_unique[bg_unique == 1]
tract_nas[tract_nas > 0]
#Missing data will be imputed for variables with less that 10% missing
missing_data_cutoff_bg <- round(nrow(stJoesBlockGroup * .1), 0)
missing_data_cutoff_tr <- round(nrow(stJoesTract * .1), 0)
#Missing data will be imputed for variables with less that 10% missing
missing_data_cutoff_bg <- round(nrow(stJoesBlockGroup) * .1, 0)
missing_data_cutoff_tr <- round(nrow(stJoesTract) * .1, 0)
bg_nas[bg_nas < missing_data_cutoff_bg]
tract_nas[tract_nas < missing_data_cutoff_tr]
names(bg_nas[bg_nas < missing_data_cutoff_bg])
names(bg_nas[bg_nas < missing_data_cutoff_bg])
names(tract_nas[tract_nas < missing_data_cutoff_tr])
#Find which variables will be kept after imputation
bg_vars <- names(bg_nas[bg_nas < missing_data_cutoff_bg])
tr_vars <- names(tract_nas[tract_nas < missing_data_cutoff_tr])
#Also eliminate vars with only one value
tr_unique <- sapply(minus_margins_tr, function(x){length(unique(x))})
bg_unique <- sapply(minus_margins_bg, function(x){length(unique(x))})
#Filter columns with less than required NA's or 1 unique value
filtered_bg <- minus_margins_bg[, bg_nas < missing_data_cutoff_bg & bg_unique > 1]
filtered_tr <- minus_margins_tr[, tr_nas < missing_data_cutoff_tr & tr_unique > 1]
library(tidycensus)
library(dplyr)
library(stringr)
library(leaflet)
setwd("~/GitHub/DS-Now-Final-Project")
#Load the data
load("census_data.RData")
#Get rid of margins of error for now
minus_margins_tr <- stJoesTract %>%
select(-ends_with('M', ignore.case = F))
#Get rid of margins of error for now
minus_margins_bg <- stJoesBlockGroup %>%
select(-ends_with('M', ignore.case = F))
#Find the number of missing values for each dataset
tr_nas <- sapply(minus_margins_tr, function(x){sum(is.na(x))})
bg_nas <- sapply(minus_margins_bg, function(x){sum(is.na(x))})
#Missing data will be imputed for variables with less that 10% missing
missing_data_cutoff_bg <- round(nrow(stJoesBlockGroup) * .1, 0)
missing_data_cutoff_tr <- round(nrow(stJoesTract) * .1, 0)
#Find which variables will be kept after imputation
bg_vars <- names(bg_nas[bg_nas < missing_data_cutoff_bg])
tr_vars <- names(tr_nas[tract_nas < missing_data_cutoff_tr])
#Also eliminate vars with only one value
bg_unique <- sapply(minus_margins_bg, function(x){length(unique(x))})
tr_vars <- names(tr_nas[tr_nas < missing_data_cutoff_tr])
#Also eliminate vars with only one value
bg_unique <- sapply(minus_margins_bg, function(x){length(unique(x))})
tr_unique <- sapply(minus_margins_tr, function(x){length(unique(x))})
#Filter columns with less than required NA's or 1 unique value
filtered_bg <- minus_margins_bg[, bg_nas < missing_data_cutoff_bg & bg_unique > 1]
filtered_tr <- minus_margins_tr[, tr_nas < missing_data_cutoff_tr & tr_unique > 1]
library(mice)
#See what type of missing the data is
mcar_test_bg <- TestMCARNormality(filtered_bg)
library(MissMech)
install.packages(MissMech)
install.packages("MissMech")
library(MissMech)
#See what type of missing the data is
mcar_test_bg <- TestMCARNormality(filtered_bg)
#See what type of missing the data is
mcar_test_bg <- TestMCARNormality(filter(filtered_bg, is.numeric))
#See what type of missing the data is
mcar_test_bg <- TestMCARNormality(select_if(filtered_bg, is.numeric))
#Impute missing data
imputed_data_bg <- mice(stJoesBlockGroup, m = 10, maxit = 20,
pred = quickpred(testData, minpuc = .2, mincor = .01),
print = FALSE)
#Impute missing data
imputed_data_bg <- mice(stJoesBlockGroup, m = 10, maxit = 20,
pred = quickpred(stJoesBlockGroup, minpuc = .2, mincor = .01),
print = FALSE)
#Impute missing data
imputed_data_bg <- mice(select_if(stJoesBlockGroup, is.numeric) m = 10, maxit = 20,
pred = quickpred(stJoesBlockGroup, minpuc = .2, mincor = .01),
print = FALSE)
#Impute missing data
imputed_data_bg <- mice(select_if(stJoesBlockGroup, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(stJoesBlockGroup, minpuc = .2, mincor = .01),
print = FALSE)
select_if(stJoesBlockGroup, is.numeric)
#Impute missing data
imputed_data_bg <- mice(select_if(filtered_bg, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(stJoesBlockGroup, minpuc = .2, mincor = .01),
print = FALSE)
TestMCARNormality(filtered_bg)
TestMCARNormality(select_if(filtered_bg, is.numeric))
#Impute missing data
imputed_data_bg <- mice(select_if(filtered_bg, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(select_if(filtered_bg, is.numeric), minpuc = .2, mincor = .01),
print = FALSE)
imputed_data_tr <- mice(select_if(filtered_tr, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(select_if(filtered_tr, is.numeric),
minpuc = .2,
mincor = .01),
print = FALSE)
plot(imputed_data_bg, layout = c(2, 1))
#Impute missing data
imputed_data_bg <- mice(select_if(filtered_bg, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(select_if(filtered_bg, is.numeric),
minpuc = .2,
mincor = .01),
print = FALSE,
seed = 300)
imputed_data_tr <- mice(select_if(filtered_tr, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(select_if(filtered_tr, is.numeric),
minpuc = .2,
mincor = .01),
print = FALSE,
seed = 300)
imputed_data_tr <- mice(select_if(filtered_tr, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(select_if(filtered_tr, is.numeric),
minpuc = .2,
mincor = .01),
print = FALSE,
seed = 1942)
#For the tracts, limit to what is in the block groups
filtered_tr <- minus_margins_tr[, colnames(minus_margins_tr) %in% colnames(minus_margins_bg)]
#Filter columns with less than required NA's or 1 unique value
filtered_bg <- minus_margins_bg[, bg_nas < missing_data_cutoff_bg & bg_unique > 1]
#For the tracts, limit to what is in the block groups
filtered_tr <- minus_margins_tr[, colnames(minus_margins_tr) %in% colnames(filtered_bg)]
imputed_data_tr <- mice(select_if(filtered_tr, is.numeric),
m = 10,
maxit = 20,
pred = quickpred(select_if(filtered_tr, is.numeric),
minpuc = .2,
mincor = .01),
print = FALSE,
seed = 1942)
#Preform PCA
pca_bg = with(data = imputed_data_bg,
exp = prcomp(center = T, scale. = T))
#Preform PCA
pca_bg = with(data = imputed_data_bg$data[1],
exp = prcomp(center = T, scale. = T))
pca_bg <- prcomp(x = imputed_data_bg$data[1],
rank. = 30,
center = TRUE,
scale. = TRUE)
summary(pca_bg)
#Preform PCA
pca_bg <- prcomp(x = imputed_data_bg$data,
rank. = 30,
center = TRUE,
scale. = TRUE)
imputed_data_bg$data
imputed_data_bg$imp
imputed_data_bg$version
imputed_data_bg$m
imputed_data_bg$imp
imputed_data_bg$predictorMatrix
complete(imputed_data_bg, 1)
#Preform PCA
pca_bg <- prcomp(x = complete(imputed_data_bg, 1),
rank. = 30,
center = TRUE,
scale. = TRUE)
summary(pca_bg)
#Preform PCA
pca_bg <- prcomp(x = complete(imputed_data_bg, 1),
rank. = 35,
center = TRUE,
scale. = TRUE)
summary(pca_bg)
num_centers <- seq(from = 2, to = 15, by = 1)
tot_withinss_bg <- rep(0, length(num_centers))
for (i in 1:length(num_centers)) {
kmeans_model_bg <- kmeans(pca_bg$x, num_centers[i])
tot_withinss_bg[i] <- kmeans_model_bg$tot.withinss
}
plot(num_centers, tot_withinss_bg)
kmeans_five_bg <- kmeans(pca_bg$x, 5)
kmeans_five_bg <- kmeans(pca_bg$x, 5)
center_info_bg <- data.frame(kmeans_five_bg$centers)
kmeans_five_bg$size
center_info_bg
Xhat = kmeans_five_bg$x[,1:35] %*% t(kmeans_five_bg$rotation[,1:35])
Xhat = kmeans_five_bg$x[,1:35] %*% t(kmeans_five_bg$rotation[,1:35])
t(kmeans_five_bg$rotation[,1:35]
t(kmeans_five_bg$rotation[,1:35])
Xhat = kmeans_five_bg$x[,1:35] %*% t(as.matrix(kmeans_five_bg$rotation[,1:35]))
t(t(pca_bg$x %*% t(pca_bg$rotation)) * pca_bg$scale + pca$center)
t(t(pca_bg$x %*% t(pca_bg$rotation)) * pca_bg$scale + pca_bg$center)
kmeans_five_bg <- kmeans(pca_bg$x, 5)
center_info_bg <- data.frame(kmeans_five_bg$centers)
kmeans_five_bg$size
center_info_bg
pca_bg$rotation
t(pca_bg$rotation)
t(pca_bg$rotation) %*% center_info_bg
t(pca_bg$rotation) %*% as.matrix(center_info_bg)
?prcomp
save.image("clusteringWork.RData")
